{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission 8\n",
    "I realized I never removed outliers because I was trying to keep as much data as possible\n",
    "\n",
    "(Submission 7 notebook copied, which includes train3 data and test2 - this has been my best submission so far)\n",
    "I will do a box plot to see if there are outliers of Saleprice to remove and then run my linear regression again to see if that improves the prediction\n",
    "\n",
    "I will comment on anything new\n",
    "\n",
    "Since this was my last notebook/ submission, I also used this notebook to make many of my visuals for my presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./datasets/train3.csv does not exist: './datasets/train3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b0c2f7bf563d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./datasets/train3.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./datasets/test2.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File ./datasets/train3.csv does not exist: './datasets/train3.csv'"
     ]
    }
   ],
   "source": [
    "train3 = pd.read_csv('./datasets/train3.csv')\n",
    "test2 = pd.read_csv('./datasets/test2.csv')\n",
    "train3.set_index('Id', inplace=True)\n",
    "test2.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.boxplot(train3['SalePrice'])\n",
    "plt.title('Distribution of Sale Price', size=20)\n",
    "plt.ylabel('Price', size=15);\n",
    "plt.savefig('./images/price_dist_outliers.png')\n",
    "#There seems to be a lot of outliers in the higher sale prices\n",
    "#https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\n",
    "#https://chartio.com/resources/tutorials/how-to-save-a-plot-to-a-file-using-matplotlib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine Z score for Sale Price in the train dataset\n",
    "from scipy import stats\n",
    "z = np.abs(stats.zscore(train3['SalePrice']))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outliers are anything more than 3 zscores/ 3 standard deviations away from the mean\n",
    "threshold = 3\n",
    "outliers = np.where(z>3)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a column for outliers, 1 is an outlier, 0 is not\n",
    "train3['outliers'] = np.where(z>3, 1,0)\n",
    "train3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only the rows which have a 0 value for outliers column, meaning they are not an outlier\n",
    "train3 = train3[train3['outliers']==0]\n",
    "train3.shape\n",
    "#This dropped 33 outliers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.boxplot(train3['SalePrice'])\n",
    "plt.title('Distribution of Sale Price', size=20)\n",
    "plt.ylabel('Price', size=15)\n",
    "plt.savefig('./images/price_dist_no_outliers.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I also noticed there were two extra points that are very off\n",
    "#When I originally made the Gr Liv Area v. Sale Price scatter plot, the two extra points had Gr Liv Areas over 5000 square feet\n",
    "#I dropped those two points as well\n",
    "train3 = train3[train3['Gr Liv Area'] < 4900]\n",
    "train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nb_dum = pd.get_dummies(train3['Neighborhood'])\n",
    "train_nb_dum['SalePrice'] = train3['SalePrice']\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(train_nb_dum.corr()[['SalePrice']], annot=True, cmap='YlGnBu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean sale price by neighborhood\n",
    "train3['SalePrice'].groupby(train3['Neighborhood']).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a bar graph of the mean sale price per neighborhood\n",
    "x_plot = sorted([hood for hood in train3['Neighborhood'].unique()])\n",
    "y_plot = train3['SalePrice'].groupby(train3['Neighborhood']).mean()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(x_plot, y_plot)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Average Sale Price per Neighborhood', size=20)\n",
    "plt.xlabel('Neighborhood', size=15)\n",
    "plt.ylabel('Average Sale Price ($)', size=15)\n",
    "plt.savefig('./images/avg_price_neighborhood.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick NoRidge, NridgHt, StoneBr - a lot of the outliers were in these neighborhoods, the correlations are now lower\n",
    "#Somerst now has a higher correlation than StoneBr so I will add that one to the neighborhood dummy column\n",
    "train3['4nbs'] = train_nb_dum['NoRidge']+train_nb_dum['NridgHt']+train_nb_dum['StoneBr']+train_nb_dum['Somerst']\n",
    "test_nb_dum = pd.get_dummies(test2['Neighborhood'])\n",
    "test2['4nbs'] = test_nb_dum['NoRidge']+test_nb_dum['NridgHt']+test_nb_dum['StoneBr']+test_nb_dum['Somerst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2['4nbs'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_adj(x, y, k):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x, y)\n",
    "    null_pred=y.mean()\n",
    "    null_resids = y-null_pred\n",
    "    null_sse = (null_resids**2).sum()\n",
    "    pred = lr.predict(x)\n",
    "    resids = y - pred\n",
    "    sse=(resids**2).sum()\n",
    "    r2 = 1-((sse) / (null_sse))\n",
    "    n = len(y)\n",
    "    r2_adj = 1 - (1-r2)*(n-1)/(n-k-1)\n",
    "    return r2_adj\n",
    "\n",
    "def run_metrics(x,y, k):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x, y)\n",
    "    pred = lr.predict(x)\n",
    "    resids = y - pred\n",
    "    r2 = lr.score(x,y)\n",
    "    mae = metrics.mean_absolute_error(y, pred)\n",
    "    sse = (resids**2).sum()\n",
    "    rmse = metrics.mean_squared_error(y, pred, squared=False)\n",
    "    mse = metrics.mean_squared_error(y, pred)\n",
    "    r2a = r2_adj(x,y,k)\n",
    "    print(f'Mean Adjusted errors: {mae}')\n",
    "    print(f'Sum Squared Errors: {sse}')\n",
    "    print(f'Mean Square Errors: {mse}' )\n",
    "    print(f'Root Mean Square Errors: {rmse}')\n",
    "    print(f'R2: {r2}')\n",
    "    print(f'Adjusted R2: {r2a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Overall Qual', 'Gr Liv Area', 'Garage Area', 'Total Bsmt SF', '1st Flr SF', 'Year Built', 'Full Bath', \n",
    "            'Qual_Cond', 'lot_liv', 'TotRms AbvGrd', 'Garage Yr Blt', 'Overall Cond', 'Kitchen AbvGr', 'Bedroom AbvGr', \n",
    "           'high_qual_fp', 'paved_street', '4nbs']\n",
    "X = train3[features]\n",
    "y = train3['SalePrice']\n",
    "run_metrics(X,y,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "linreg=LinearRegression()\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 Train {linreg.score(X_train, y_train)}')\n",
    "print(f'RMSE Train {metrics.mean_squared_error(y_train, linreg.predict(X_train), squared=False)}')\n",
    "print(f'R2 Test {linreg.score(X_test, y_test)}')\n",
    "print(f'RMSE Test {metrics.mean_squared_error(y_test, linreg.predict(X_test), squared=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso coding commented in submission7 journal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "Z_train = sc.fit_transform(X_train)\n",
    "Z_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(Z_train, y_train)\n",
    "linreg.score(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.score(Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_alphas = np.logspace(0,5, 100)\n",
    "lasso_cv = LassoCV(alphas = l_alphas, cv=5)\n",
    "lasso_cv.fit(Z_train, y_train)\n",
    "print(f'Accuracy Lasso train: {lasso_cv.score(Z_train, y_train)}')\n",
    "print(f'Accuracy Lasso test: {lasso_cv.score(Z_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_sc = sc.fit_transform(test2[features])\n",
    "test2['SalePrice2'] = lasso_cv.predict(test2_sc)\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linreg output without outliers\n",
    "output8 = test2[['SalePrice']]\n",
    "output8.rename(columns = {'SalePrice2':'SalePrice'}, inplace = True)\n",
    "output8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output8.to_csv('./datasets/dana_submission_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINEAR coefficient dataframe\n",
    "train3_coefs = train3[features]\n",
    "train3_coefs.head()\n",
    "coefs = pd.DataFrame({'column': train3_coefs.columns, 'coef': linreg.coef_})\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train, lasso_cv.predict(Z_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train, lasso_cv.predict(Z_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LASSO coeffieicents\n",
    "pd.DataFrame({'column':X.columns, 'coef':lasso_cv.coef_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can remove all features which have a coefficient of 0\n",
    "#This means the LASSO regression said they were not important\n",
    "features = ['Overall Qual', 'Gr Liv Area', 'Garage Area', 'Total Bsmt SF', '1st Flr SF', 'Year Built', \n",
    "            'Qual_Cond', 'Garage Yr Blt', 'Kitchen AbvGr', 'high_qual_fp', '4nbs']\n",
    "X = train3[features]\n",
    "y = train3['SalePrice']\n",
    "run_metrics(X,y,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "linreg=LinearRegression()\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 train {linreg.score(X_train, y_train)}')\n",
    "print(f'R2 test{linreg.score(X_test, y_test)}')\n",
    "print()\n",
    "print(f'RMSE train {metrics.mean_squared_error(y_train, linreg.predict(X_train), squared=False)}')\n",
    "print(f'RMSE test {metrics.mean_squared_error(y_test, linreg.predict(X_test), squared=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual price vs Predicted price\n",
    "#The diagonal line is where x=y, this is where a point would be if the model predicted the actual sale price\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_train, linreg.predict(X_train), alpha=0.5)\n",
    "plt.title('Actual vs. Predicted Price for Training Data', size = 20)\n",
    "plt.xlabel('Actual Price', size=15)\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel('Predicted Price', size=15)\n",
    "lineStart = y_train.min() \n",
    "lineEnd = y_train.max()  \n",
    "\n",
    "plt.plot([lineStart, lineEnd], [lineStart, lineEnd], 'k-', color = 'r')\n",
    "plt.xlim(lineStart, lineEnd)\n",
    "plt.ylim(lineStart, lineEnd)\n",
    "plt.show()\n",
    "plt.savefig('./images/actual_pred_train.png');\n",
    "#Noah sent me this link! https://stackoverflow.com/questions/40516661/adding-line-to-scatter-plot-using-pythons-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.regplot(y_train,\n",
    "            linreg.predict(X_train),\n",
    "            scatter_kws={'alpha' : 0.5}, \n",
    "            line_kws={'color':'red'}).set_title('Actual vs. Predicted Price for Training Data', size = 20)\n",
    "plt.ylabel('Predicted Price', size=15)\n",
    "plt.xlabel('Actual Price', size=15);\n",
    "#Thank you Noah!!!!\n",
    "#I want a line where y=x to show how close the predictions are to the actual value - this is the right plot for that, see above\n",
    "#Good to know this type of plot exists!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.regplot(y_test,\n",
    "            linreg.predict(X_test),\n",
    "            scatter_kws={'alpha' : 0.5, 'color':'red'}, \n",
    "            line_kws={'color':'blue'}).set_title('Actual vs. Predicted Price for Testing Data', size = 20)\n",
    "plt.ylabel('Predicted Price', size=15)\n",
    "plt.xlabel('Actual Price', size=15);\n",
    "#Thank you Noah!!!!\n",
    "#Same as the other SNS plot, this is not the right one for what I was trying to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual price vs Predicted price\n",
    "#The diagonal line is where x=y, this is where a point would be if the model predicted the actual sale price\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_test, linreg.predict(X_test), alpha=0.5, color='red')\n",
    "plt.title('Actual vs. Predicted Price for Testing Data', size = 20)\n",
    "plt.xlabel('Actual Price', size=15)\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel('Predicted Price', size=15)\n",
    "lineStart = y_test.min() \n",
    "lineEnd = y_test.max()  \n",
    "\n",
    "plt.plot([lineStart, lineEnd], [lineStart, lineEnd], 'k-', color = 'b')\n",
    "plt.xlim(lineStart, lineEnd)\n",
    "plt.ylim(lineStart, lineEnd)\n",
    "plt.show()\n",
    "plt.savefig('./images/actual_pred_test.png');\n",
    "#Noah sent me this link! https://stackoverflow.com/questions/40516661/adding-line-to-scatter-plot-using-pythons-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot of Above Grade Living vs Sale Price\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(train3['Gr Liv Area'], train3['SalePrice'])\n",
    "plt.title('Above Grade Living Area vs Sale Price', size = 20)\n",
    "plt.xlabel('Above Grade Living Area (Sq Ft)', size=15)\n",
    "plt.ylabel('Sale Price ($)', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot of Year Built vs Sale Price\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(train3['Year Built'], train3['SalePrice'])\n",
    "plt.title('Year Built vs Sale Price', size = 20)\n",
    "plt.xlabel('Year Built', size=15)\n",
    "plt.ylabel('Sale Price ($)', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear coeffs with the ones removed, as designated by the lasso regression\n",
    "pd.DataFrame({'column':X.columns, 'coef':linreg.coef_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot of Kitched Above Grade vs Sale Price\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(train3['Kitchen AbvGr'], train3['SalePrice'])\n",
    "plt.title('Kitchens Above Grade vs Sale Price', size = 20)\n",
    "plt.xlabel('Number of Kitchens Above Grade', size=15)\n",
    "plt.ylabel('Sale Price ($)', size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, I finally realized the outliers and remove them. I will do this in my first notebook during the next project and the rest of my data science career. I'm glad I learned this lesson now.\n",
    "\n",
    "I also used this notebook to make my visuals for my presentation, since it was my best model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
